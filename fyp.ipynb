{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "rowsToCluster = pd.DataFrame()\n",
    "startRampPath = 'data/BLM/start_ramp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRowWithBlmMax(blmData):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "        blmData : DataFrame -- DataFrame loaded from the BLM data file, without timestamp column\n",
    "    Returns\n",
    "        DataFrame with row with the max BLM value in the provided data\n",
    "    \"\"\"\n",
    "    \n",
    "    blmMax = blmData.max() # Series of column num (i.e. BLM num) -> maximum value for that column\n",
    "    blmMaxOverall = blmData.values.max() # max BLM value in the whole dataset\n",
    "    rowIndexWithBlmMaxOverall = blmData.idxmax()[blmMax[blmMax == blmMaxOverall].index]\n",
    "    rowWithBlmMaxOverall = blmData.loc[rowIndexWithBlmMaxOverall]\n",
    "    \n",
    "    assert rowWithBlmMaxOverall.max().max() == blmMaxOverall\n",
    "    #TODO what if more than one row contains the same blmMaxOverall?\n",
    "    assert len(rowWithBlmMaxOverall.index) == 1\n",
    "    \n",
    "    return rowWithBlmMaxOverall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(startRampPath):\n",
    "    # load BLM data file as a DataFrame\n",
    "    blmData = pd.read_csv(startRampPath + '/' + file, sep=' ', header=None)\n",
    "    \n",
    "    # Delete first column (contains timestamps)\n",
    "    blmData = blmData.drop(columns=0)\n",
    "    \n",
    "    rowsToCluster = rowsToCluster.append(getRowWithBlmMax(blmData), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster memberships:\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(rowsToCluster)\n",
    "print(\"Cluster memberships:\\n{}\".format(kmeans.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "blmLabels = np.genfromtxt('data/blm_labels.txt', dtype='str')\n",
    "beam1BlmLabels = np.genfromtxt('data/beam1_blm_labels.txt', dtype='str')\n",
    "beam2BlmLabels = np.genfromtxt('data/beam2_blm_labels.txt', dtype='str')\n",
    "\n",
    "rowsToCluster.columns = blmLabels\n",
    "\n",
    "# Extract out of rowsToCluster BLMs associated with beam 1, and BLMs associated with Beam 2\n",
    "\n",
    "beam1BlmData = rowsToCluster.filter(items=beam1BlmLabels); \n",
    "beam2BlmData = rowsToCluster.filter(items=beam2BlmLabels);\n",
    "\n",
    "beam2BlmData.columns = beam1BlmLabels; # so that Beam 1 and Beam 2 data can merge under the same 'logical' BLM labels\n",
    "# NB - chose to use beam1BlmLabels arbitrarily - could have just as well used beam2.\n",
    "\n",
    "mergedBlmData = pd.concat([beam1BlmData, beam2BlmData], keys=['B1', 'B2'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
